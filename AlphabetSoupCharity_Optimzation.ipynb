{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAv4WGZxQYiH",
        "outputId": "8dddbf99-7e47-4253-95d9-f5ab25ff2eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EWrTyHXQYiP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JynH06dqQYiW"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"/content/drive/MyDrive/deep-learning-challenge/Resources/charity_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Epk9-B2PQYiY"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(['EIN', 'NAME'], axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvfO-ET0QYiZ",
        "outputId": "8f864b0d-a831-461b-d6ac-50695080aa4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b38XXFxnQYiZ",
        "outputId": "86f1a677-1aeb-4035-a81f-0dc0c3e9ccfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of application types to be replaced\n",
        "application_types_to_replace = ['T13','T12', 'T2', 'T14', 'T25', 'T15', 'T29', 'T17','T9']\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfC_r2AlQYia",
        "outputId": "4aeced90-cb89-4e97-cb5d-7b3710d7a372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of classifications to be replaced\n",
        "classifications_to_replace = ['C7000','C1700','C4000',\n",
        "                              'C5000','C1270',\n",
        "                              'C2700','C2800','C7100',\n",
        "                              'C1300','C1280','C1230',\n",
        "                              'C1400','C7200','C2300',\n",
        "                              'C1240','C8000','C7120',\n",
        "                              'C1500','C1800','C6000',\n",
        "                              'C1250','C8200','C1238',\n",
        "                              'C1278','C1235','C1237',\n",
        "                              'C7210','C2400','C1720',\n",
        "                              'C4100','C1257','C1600',\n",
        "                              'C1260','C2710','C0',\n",
        "                              'C3200','C1234','C1246',\n",
        "                              'C1267','C1256','C4120',\n",
        "                              'C8210','C2561','C4500',\n",
        "                              'C2150','C2570','C1820',\n",
        "                              'C6100','C1248','C2600',\n",
        "                              'C1370','C5200','C4200',\n",
        "                              'C2190','C1236','C2500',\n",
        "                              'C1580','C3700','C1570',\n",
        "                              'C1283','C2380','C1732',\n",
        "                              'C1728','C2170','C1245',\n",
        "                              'C1900'\n",
        "                              ]\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAWcQUC2QYic",
        "outputId": "ed696306-2c9a-488f-e3a4-84d3c3bcaf8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                24388\n",
              "25000-99999       3747\n",
              "100000-499999     3374\n",
              "1M-5M              955\n",
              "1-9999             728\n",
              "10000-24999        543\n",
              "10M-50M            240\n",
              "5M-10M             185\n",
              "50M+               139\n",
              "Name: INCOME_AMT, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look to see if can bin `INCOME_AMT` into fewer groups to limit features\n",
        "application_df['INCOME_AMT'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "-wmlZay7QYi1",
        "outputId": "ee581af4-3077-4aa0-e44a-c7e658f6dad2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f64a4290890>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEECAYAAAABJn7JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWDElEQVR4nO3df5Dc9X3f8edbpwMVmdYQBIUIWbZL4eBwLbiJYyBtzu4fkB+GOgRzxYCj89BMoqviGUeJe8zYZEIzKCaOIv8Yq+YSSNx1GurSKQQnU+cwPeRgnyzJCMnYjgEhoEi2YltcR+g4vfvHfu+0Op90K7jVfnf3+Zi50e735/v2q3t9P/vZ73c/kZlIksprUbMLkCQdn0EtSSVnUEtSyRnUklRyBrUklZxBLUkl17CgjoiRiNgbETvqWPZNEfHliPhmRDwSEcsbVZcktZpGtqj/DLi6zmU/DtyXmW8Dfg/4g0YVJUmtpmFBnZmPAvtrp0XEWyPiSxGxJSL+T0RcVMy6GPi74vEocG2j6pKkVnOy+6g3AUOZeTnwYeDTxfTtwHuLx/8OOD0ifuok1yZJpbT4ZO0oIt4AXAH8VURMTz61+PfDwCcj4gPAo8DzwNTJqk2SyuykBTXV1vsPM/Pts2dk5gsULeoi0H8lM394EmuTpNI6aV0fmflj4OmI+FWAqPpXxeOzImK6lo8AIyerLkkqu0ZenlcBvgpcGBF7ImIQuAkYjIjtwJMc+dDw54GnIuLbwDnAnY2qS5JaTfg1p5JUbt6ZKEkl15APE88666xcuXJlIzYtSW1py5Yt38/MZXPNa0hQr1y5kvHx8UZsWpLaUkQ8e6x5dn1IUskZ1JJUcga1JJWcQS1JJWdQS1LJGdTqCJVKhd7eXrq6uujt7aVSqTS7JKluBrXaXqVSYe3atUxMTAAwMTHB2rVrDWu1DINabW/dunUsXryYkZERDh48yMjICIsXL2bdunXNLk2qi0Gttrdnzx7uvfde+vv76e7upr+/n3vvvZc9e/Y0uzSpLga1JJWcQa22t3z5cm655RZGR0eZnJxkdHSUW265heXLHexercGgVttbv349U1NTrF69mlNPPZXVq1czNTXF+vXrm12aVBeDWm1vYGCADRs2sHTpUiKCpUuXsmHDBgYGBppdmlSXhgwc0NfXl357niTVLyK2ZGbfXPNsUUtSyRnUklRyBrUklZxBLUklZ1BLUsnVFdQR8aGIeDIidkREJSKWNLowSVLVvEEdET8N/EegLzN7gS7gxkYXJkmqqrfrYzHwTyJiMXAa8ELjSpIk1Zo3qDPzeeDjwG7gReBHmfm3s5eLiNsiYjwixvft27fwlUpSh6qn6+MM4FrgzcB5wNKIeP/s5TJzU2b2ZWbfsmXLFr5SSepQ9XR9/Fvg6czcl5mTwBeBKxpbliRpWj1BvRv42Yg4LSICeDewq7FlSZKm1dNH/ThwP/AN4IlinU0NrkuSVFhcz0KZ+VHgow2uRZI0B+9MlKSSM6glqeQMakkqOYNakkrOoJakkjOoJankDGpJKjmDWpJKzqCWpJIzqCWp5AxqSSo5g1qSSs6glqSSM6glqeQMakkqOYNakkrOoJakkjOoJankDGpJKjmDWpJKzqCWpJIzqCWp5AxqSSo5g1qSSs6glqSSM6glqeQMakkqOYNakkrOoJakkjOoJankDGpJKjmDWpJKzqCWpJIzqCWp5AxqSSo5g1qSSs6glqSSqyuoI+KNEXF/RHwrInZFxDsbXZgkqWpxncttAL6UmddHxCnAaQ2sSZJUY96gjoh/Bvxr4AMAmXkIONTYsiRJ0+rp+ngzsA/404jYGhGfi4ilsxeKiNsiYjwixvft27fghUpSp6onqBcDlwGfycxVwATwu7MXysxNmdmXmX3Lli1b4DIlqXPVE9R7gD2Z+Xjx/H6qwS1JOgnmDerM/L/AcxFxYTHp3cDOhlYlSZpR71UfQ8Dniys+vgf8WuNKkiTVqiuoM3Mb0NfgWiRJc/DORHWESqVCb28vXV1d9Pb2UqlUml2SVLd6uz6kllWpVBgeHuaee+7hqquuYmxsjMHBQQAGBgaaXJ00v8jMBd9oX19fjo+PL/h2pdeit7eXjRs30t/fPzNtdHSUoaEhduzY0cTKpCMiYktmztnFbFCr7XV1dXHw4EG6u7tnpk1OTrJkyRKmpqaaWJl0xPGC2j5qtb2enh7GxsaOmjY2NkZPT0+TKpJOjEGttjc8PMzg4CCjo6NMTk4yOjrK4OAgw8PDzS5NqosfJqrtTX9gODQ0xK5du+jp6eHOO+/0g0S1DPuoJakE7KOWpBZmUEtSyRnUklRyBrUklZxBLUklZ1BLUskZ1JJUcga1JJWcQS1JJWdQS1LJGdSSVHIGtSSVnEEtSSVnUEtSyRnU6giOQq5W5sABanuOQq5W58ABanuOQq5W4Cjk6miOQq5W4Agv6miOQq5WZ1Cr7TkKuVqdHyaq7TkKuVqdfdSSVAL2UUtSCzOoJankDGpJKjmDWpJKzqCWpJIzqCWp5AxqSSq5uoM6IroiYmtEPNjIgiRJRzuRFvVaYFejCpEkza2uoI6I5cAvAp9rbDmSpNnqbVH/MbAOOHysBSLitogYj4jxffv2LUhxkqQ6gjoifgnYm5lbjrdcZm7KzL7M7Fu2bNmCFShJna6eFvWVwHsi4hngC8C7IuIvGlqVJGnGvEGdmR/JzOWZuRK4Efi7zHx/wyuTJAFeRy1JpXdCAwdk5iPAIw2pRJI0J1vUklRyBrUklZxBLUklZ1BLUskZ1JJUcga1OkKlUqG3t5euri56e3upVCrNLkmq2wldnie1okqlwvDwMPfccw9XXXUVY2NjDA4OAjAwMNDk6qT5RWYu+Eb7+vpyfHx8wbcrvRa9vb1s3LiR/v7+mWmjo6MMDQ2xY8eOJlYmHRERWzKzb855BrXaXVdXFwcPHqS7u3tm2uTkJEuWLGFqaqqJlUlHHC+o7aNW2+vp6WFsbOyoaWNjY/T09DSpIunEGNRqe8PDwwwODjI6Osrk5CSjo6MMDg4yPDzc7NKkuvhhotre9AeGQ0ND7Nq1i56eHu68804/SFTLsI9akkrAPmpJamEGtSSVnEEtSSVnUEtSyRnUklRyBrUklZxBLUklZ1BLUskZ1JJUcga1JJWcQS1JJWdQS1LJGdSSVHIGtSSVnEEtSSVnUEtSyRnUklRyBrU6QqVSobe3l66uLnp7e6lUKs0uSaqbQa22V6lUWLt2LRMTE2QmExMTrF271rBWyzCo1fbWrVtHV1cXIyMjvPLKK4yMjNDV1cW6deuaXZpUF4NabW/Pnj3cd9999Pf3093dTX9/P/fddx979uxpdmlSXQxqSSo5g1ptb/ny5dx6662Mjo4yOTnJ6Ogot956K8uXL292aVJdDGq1vfXr1/Pqq6+yevVqlixZwurVq3n11VdZv359s0uT6jJvUEfE+RExGhE7I+LJiFh7MgqTFsrAwAAbNmxg6dKlACxdupQNGzYwMDDQ5Mqk+kRmHn+BiHOBczPzGxFxOrAFuC4zdx5rnb6+vhwfH1/YSiWpjUXElszsm2vevC3qzHwxM79RPD4A7AJ+emFLlBrLG17UyhafyMIRsRJYBTw+x7zbgNsAVqxYsQClSQujUqkwPDzMPffcw1VXXcXY2BiDg4MAdn+oJczb9TGzYMQbgK8Ad2bmF4+3rF0fKpPe3l42btxIf3//zLTR0VGGhobYsWNHEyuTjjhe10ddQR0R3cCDwN9k5h/Nt7xBrTLp6uri4MGDdHd3z0ybnJxkyZIlTE1NNbEy6YjX1UcdEQHcA+yqJ6Slsunp6eGOO+44qo/6jjvuoKenp9mlSXWp5zrqK4GbgXdFxLbi5xcaXJe0YPr7+7nrrrtYvXo1Bw4cYPXq1dx1111HdYVIZVZ3H/WJsOtDZdLb28sFF1zAww8/zCuvvMKpp57KNddcw3e+8x37qFUar6vrQ2p1O3fuZPv27Tz88MMcOnSIhx9+mO3bt7Nz5zFvBZBKxaBW2zvllFNYs2bNUd+et2bNGk455ZRmlybVxaBW2zt06BAbN2486kuZNm7cyKFDh5pdmlSXE7rhRWpFF198Mddddx1DQ0Ps2rWLnp4ebrrpJh544IFmlybVxaBW2xseHmbt2rUsXbp0ZiiuTZs2sWHDhmaXJtXFoFZHOHDgAPv27QPgmWeeYcmSJU2uSKqffdRqe2vWrGFycpK7776biYkJ7r77biYnJ1mzZk2zS5PqYlCr7e3fv58bbriBkZERTj/9dEZGRrjhhhvYv39/s0uT6mJQqyM89NBDTExMADAxMcFDDz3U5Iqk+hnU6ggHDhxgaGjoqH+lVuEt5Gp7EUFEcPbZZ/PSSy9xzjnnsHfvXjKTRvz/l14LbyFXx1u1ahV79+4FYO/evaxatarJFUn1M6jV9s4880y2bt3K2WefPdOy3rp1K2eeeWazS5PqYlCro9jVoVZkUKvt7d+/f86uDy/PU6swqNURtm7dyqJF1f/uixYtYuvWrU2uSKqft5CrI2TmzPiIjpOoVmOLWpJKzqBWxzjjjDOICM4444xmlyKdEINaHeP222/n5Zdf5vbbb292KdIJ8c5Etb2IOOY8L9dTWXhnoiS1MINakkrOoFZH6OrqOu5zqcwManWESy+9lEsuuYRFixZxySWXcOmllza7JKlu3vCijrBt27aZx08++WQTK5FOnC1qSSo5g1qSSs6gVkdYtGgR3d3dAHR3d898QZPUCuyjVkc4fPgwhw8fBmBycrLJ1UgnxmaFJJWcQS1JJWdQS1LJGdSSVHIGtSSVnEEtSSVnUEtSydUV1BFxdUQ8FRHfjYjfbXRRZbRixQoiYuZnxYoVzS5JUoeYN6gjogv4FHANcDEwEBEXN7qwMlmxYgXPPfccV1xxBS+88AJXXHEFzz33nGEt6aSop0X9M8B3M/N7mXkI+AJwbWPLKpfpkH7sscc499xzeeyxx2bCWpIabd4xEyPieuDqzPxg8fxm4B2ZuWbWcrcBtwGsWLHi8meffbYxFb9Ol95bju8hfuLWJ5pdQsspy7EDj99rUZbjV9Zjd7wxExfsuz4ycxOwCaqD2y7UdhfaazlIETHTop525ZVXsnnzZgdHPYle6x+Yg9uWQ1kDshXU0/XxPHB+zfPlxbSOcf7557N582auvPJKXnzxxZmQPv/88+dfWZJep3pa1F8HLoiIN1MN6BuBf9/Qqkpm9+7drFixgs2bN3PeeecB1fDevXt3kytTPTJzzla1rWm1inmDOjNfjYg1wN8AXcBIZnbcWEaGcmszlNXK6uqjzsy/Bv66wbVIkubgnYmSVHIGtSSVnEEtSSVnUEtSyc17Z+Jr2mjEPqCctya+fmcB3292EXrNPH6trZ2P35syc9lcMxoS1O0sIsaPdZunys/j19o69fjZ9SFJJWdQS1LJGdQnblOzC9Dr4vFrbR15/OyjlqSSs0UtSSVnUEtSyS3YwAGtICKGqX5F6xRwGPhH4AzgDcAy4Oli0d/IzM0RsQ34VmbeGBG/Bqwt5l8MPFVs50vAQeDlzPx4zb6eAfoy8/tz7Pc/ZObjDf1lJbWPzOyIH+CdwFeBU4vnZwHnFY9/Hnhw1vI9wBNUv4N76ax5zwBn1Tz/GPDhuZY53n79mfeYXQckcFHxfBHwJ8CO4th8HXjz7GMCXE71pLtqnu0/APz9rGkfK/b5L2qm/VYxrQ94HNgG7Ab2FY+3ASub/Xot4Ov+8nyv9zHWW10s981inWuL6Y9QbbRML7cS2FHz/GeAR6k2frYCnwNOK+ZdA4wDO4t5d9ccp+drXv9twBuB04DPF3XsAMaANxTrDANPFvVtozqk4HR9T9Vs5/rZNdbs88PF4z8Drj9Zx6STWtTnAt/PzFcAMnO+u5sGgD+nGtjXAv/1JO1XRwxQ/UMbAD4KvA84D3hbZh6OiOXARO0KEfE24H7gfZm59Vgbjog3Ug30lyPiLZn5vZrZT1AdIOP3i+e/SvUPnMx8R7H+B6iGz1Fjh7aZeV/vacW8YeCyzPxRREy/Sz2uiDgH+Cvgxsz8ajHteuD0iHgL8EngFzPzWxHRRTEua+ETWfMutlj3I8BLmXlp8fxCYDIi3gn8UlHfKxFxFnBKzao3ZeZ4zXZWzlf7ydRJfdR/C5wfEd+OiE9HxL+ZZ/n3UR1xvUI1KE7WfgUUf+hXAYNUQxOqJ70XM/MwQGbuycx/rFmth2or+ebM/No8u3gv8L+oHuMbZ817gOrJmYh4K/Aj2ve25eOZ7/WudTZwAHi5WPblzHz6GMvW+k3g3umQLta9PzNfAtYBd2bmt4rpU5n5mTpqnhkqMDOfKhpJP9FgyswX6qivFDomqDPzZaotqNuovmX9y6JV9BMioo/qQd0NfBlYFRFnHm/zx95t/fvVUa4FvpSZ3wZ+EBGXA/8N+OWI2BYRd0fEqlnr/E9gTWaO1bH9Aaon4blOxD8GnouIXqoh/pev5xdpYfO93rW2Ay8BT0fEn0bEL9e5j15gy2uYB/ChorZtETFaTBsBficivhoRvx8RFxTT52swfb5mWz9VZ+0nTccENcyckR/JzI8Ca4BfOcaiA8BFxQeC/wD80+MsC/ADqh9K1jod+OEJ7ldHDFBt7VL8O5CZe4ALgY9Q/VD2yxHx7pp1/jfwweIt8jEVb7cvAMaKE8FkEcq1plva1wH/4/X+Mq2ojte7dtkp4Gqq/bvfBj4RER+bnj3XKgtQ4icy8+3FT39RxzbgLcAfAmcCX4+InjoaTDfVbOsHx6mvKTeedExQR8SFNWdXgLczxzf8RcQi4Abg0sxcmZkrqbbujtf98Sjwnog4vdjGe4HtmTlV7351RPHu5V3A54qT5W8DN0REZOYrmflwZv428J+pBum06f7iT8+zixuonlifLra/kp88vg8CNwO7M/PHr+PXaWnzvN6zl83M/Fpm/gHVk9x0g2R2Q+ZMjnQlPUk1QOdyvHnHq/nlzPxiZv4G8BfALxTTT6TBNFfjq7buk6pjgprqJXj3RsTOiPgm1UvsPjbHcj8HPD+r/+pR4OKIOHeuDWfmN6l+6DFWXNL368AHT3C/OuJ64M8z803FyfJ8qldx/FxEnAczJ9S3cfRJ7zDVyyAviojfO872B4Cra07ElzOrnzoz/x/wO8CdC/Q7tZyIuGye17t22fMi4rKaSbUNkkeA98eRoeBvBaa7Kj4J3BoR76jZ1nuLdz1/CPyniPiX0zVExK/PU/OVEXFG8fgUqn9vz55og6logb8YEe8qtnUm1XcM9XSrLbiOueojM7cAVxxj3iNU/zORmV8BfnbW/Cngn9c8XznHNj4LfPZE9qtjGgDumjXtvwP3Avsj4tRi2teo/qHPyMyDEfEe4CsR8VJmfqp2fvFp/puAv69Z5+mI+FFtWBTTv0BnOxv4L8d7vWt0Ax8vgv0g1e6F6VDdBFwEbI+IpHq53UcAMvOliLixWPdsqifbR6l+PvFSRPwWUImI06h2OzxYs88PRcT7a55fB7wV+ExxUlgEPET1/85lwMbiap9Xge9y9BUkc7kF+FRE/FHx/I7M/Iea+Z+NiD8uHj+Xme+cZ3uvmd/1IUkl10ldH5LUkjqm60OdZ9Zt/9Mey8zfbEY97SIiHgdOnTX55sx8ohn1dAK7PiSp5Oz6kKSSM6glqeQMakkqOYNakkru/wPCtGIgnVZZ0gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Look to see if any outliers\n",
        "application_df.plot.box(['ASK_AMT'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jEj4QluQYi3",
        "outputId": "7ebe1c63-dd38-41fe-e5fa-18e041dbd0b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    34294\n",
              "0        5\n",
              "Name: STATUS, dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See distribution for `STATUS` and `SPECIAL_CONSIDERATIONS`\n",
        "application_df['STATUS'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATm7a7-hWHN0",
        "outputId": "5ca5f521-0ab7-4fc6-a61e-10beab5f7d61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
              "       'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS', 'ASK_AMT',\n",
              "       'IS_SUCCESSFUL'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Based on the above, groups wtih status 0 are outliers. Drop these rows and remove this column\n",
        "application_df = application_df.drop(application_df[application_df.STATUS ==0].index)\n",
        "application_df = application_df.drop(['STATUS'], axis='columns')\n",
        "application_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KprfSm4BZ0gm",
        "outputId": "cda3bc32-d2da-43c5-ceb6-4e502df4fc9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "N    34268\n",
              "Y       26\n",
              "Name: SPECIAL_CONSIDERATIONS, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See distribution for `SPECIAL_CONSIDERATIONS`\n",
        "application_df['SPECIAL_CONSIDERATIONS'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMQZWaZxaBd-",
        "outputId": "f62a9bb2-af91-4759-a69a-42e5118589d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
              "       'ORGANIZATION', 'INCOME_AMT', 'ASK_AMT', 'IS_SUCCESSFUL'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Based on the above, groups wtih special considerations Y are outliers. Drop these rows and remove this column\n",
        "application_df = application_df.drop(application_df[application_df.SPECIAL_CONSIDERATIONS =='Y'].index)\n",
        "application_df = application_df.drop(['SPECIAL_CONSIDERATIONS'], axis='columns')\n",
        "application_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXoSn7x9UW3r",
        "outputId": "f1b3a485-e813-41e3-8398-b092df994815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    18242\n",
              "0    16026\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine if Dataset is balanced.\n",
        "application_df['IS_SUCCESSFUL'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h71EkhOVVwOQ"
      },
      "source": [
        "Based on the above, the dataset is fairly balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "H0RMrx6lQYi3"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "e8V24N-rQYi6"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "# Features array\n",
        "X = application_df.drop(['IS_SUCCESSFUL'], axis='columns')\n",
        "\n",
        "# Target array\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOjxTkyoaihy",
        "outputId": "87cbe353-6a39-43e3-9e76-77cb2ed9aaa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25701, 40)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MOZgzPCOQYi8"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2zpwZh_QYi9"
      },
      "source": [
        "# Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpBXQNZOQYi-"
      },
      "source": [
        "## Baseline with new data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzQMqOfQQYi_",
        "outputId": "a66e28bf-b857-4320-bd13-734eb3bbbe76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 80)                3280      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,841\n",
            "Trainable params: 9,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "# nn.add(tf.keras.layers.Dense(units=40, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MkbQM0L6QYjB"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq8SZEP6QYjC",
        "outputId": "4c572275-348c-4ac3-960c-044c108f0614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5671 - accuracy: 0.7223\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7318\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5526 - accuracy: 0.7322\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7335\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7335\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7336\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7322\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7326\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7357\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7343\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7358\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7347\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7372\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7367\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7374\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7369\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7377\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7370\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7370\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7381\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7379\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7374\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7378\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7373\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7388\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7388\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7393\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7390\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7399\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7393\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7391\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7392\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7397\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7382\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7390\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7402\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7392\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7400\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7406\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7405\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7402\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7404\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7407\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7410\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7402\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7404\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7405\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7402\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7402\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7401\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7402\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7410\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7406\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7407\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7409\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7405\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7413\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7409\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7401\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7412\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7402\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7405\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7412\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7408\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7415\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7411\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7414\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7408\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7412\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7412\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7416\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7414\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7415\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7413\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7412\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7412\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7411\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7413\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7407\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7416\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7409\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7410\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7414\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7410\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7414\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7420\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7416\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7411\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7410\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7417\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7420\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7415\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7414\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7429\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7428\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7418\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7418\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7423\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7418\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7417\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ4Fyz8yQYjD",
        "outputId": "33f69357-4547-4a30-af5e-9c5fc8522455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5724 - accuracy: 0.7231 - 372ms/epoch - 1ms/step\n",
            "Loss: 0.5723698735237122, Accuracy: 0.7231236100196838\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaa9imOvoN37"
      },
      "source": [
        "Model is overfitt and since dataset is more or less balanced will reduce epochs. Should modify hidden layers and number of nodes to try and improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XNIS5iqQYjM"
      },
      "source": [
        "## V2 - Modify "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fulenLGDoktj",
        "outputId": "0d349fbf-cfef-4193-ffc1-65bcec825c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                930       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,801\n",
            "Trainable params: 2,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zM71y_KHojXW"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzy3z_gtpmji",
        "outputId": "0e597355-a35e-4f3d-ef8c-3af1a404e96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.7152\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5531 - accuracy: 0.7305\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5501 - accuracy: 0.7316\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7331\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7316\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7334\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7349\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7352\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7355\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7358\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7368\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7357\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7368\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7358\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7372\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7369\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7366\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7379\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7367\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7381\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7375\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7371\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7387\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7378\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7379\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7379\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7388\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7386\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7386\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7385\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7397\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7384\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7387\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7396\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7398\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7389\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7385\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7384\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7392\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7388\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7386\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7389\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7390\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7393\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7394\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7393\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7390\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7393\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7392\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfx_YjwTqAIE",
        "outputId": "aece5b51-c35e-43d2-ce30-7f3afe4e3b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5644 - accuracy: 0.7220 - 338ms/epoch - 1ms/step\n",
            "Loss: 0.564437985420227, Accuracy: 0.7219563722610474\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDd1F9FoqCGP"
      },
      "source": [
        "The model is more balanced but accuracy is still low. Will try adding an additional hidden layer and modifying activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-f85GXdqCpb"
      },
      "source": [
        "## V3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOhmLY0aqkWA",
        "outputId": "987a6058-4a1b-4296-ad04-98af5cc1a100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 30)                930       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,001\n",
            "Trainable params: 3,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"elu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=20, activation=\"elu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KX_hud5uqcSL"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-03512CqZrA",
        "outputId": "8a52bb46-a32f-4ce9-fc8c-76c09f18903b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.5308\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.5308\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5515 - accuracy: 0.5308\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.5308\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.5308\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.5308\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.5308\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.5308\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.5308\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.5308\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.5308\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.5308\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.5308\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.5308\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.5308\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.5308\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.5308\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.5308\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.5308\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.5308\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.5308\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.5308\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.5308\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.5308\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.5308\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.5308\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.5308\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.5308\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.5308\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.5308\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.5308\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.5308\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.5308\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.5308\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.5308\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.5308\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.5308\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.5308\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.5308\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.5308\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.5308\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.5308\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.5308\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.5308\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.5308\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.5308\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.5308\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.5308\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.5308\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.5308\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtK8vUSVqWxk",
        "outputId": "c068b52e-82e8-45c8-9885-4c240e56f30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5606 - accuracy: 0.5368 - 370ms/epoch - 1ms/step\n",
            "Loss: 0.5606152415275574, Accuracy: 0.5368273854255676\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqayoNZYrwuy"
      },
      "source": [
        "Well that didn't work... Keep the layers change back the activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndIMRWxerwCa"
      },
      "source": [
        "## V4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1EhF5JlrxYM",
        "outputId": "46225c0c-7058-4e41-d4ea-a0e94017c01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 80)                3280      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 60)                4860      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 40)                2440      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 20)                820       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,621\n",
            "Trainable params: 11,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=60, activation=\"tanh\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=40, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
        "\n",
        "# Fourth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "49AjQcuxsMCw"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zEgD72isItu",
        "outputId": "63ac81fc-e574-440b-9fc7-6722d3058b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5671 - accuracy: 0.7244\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7315\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7317\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7329\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7338\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7350\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7346\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7349\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7370\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7378\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7359\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7367\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7369\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7371\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7359\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7366\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7364\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7373\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7383\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7380\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7375\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7384\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7373\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7392\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7384\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7381\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7391\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7385\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7394\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7393\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7392\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7398\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7397\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7391\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7390\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7404\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7394\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7400\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7406\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7395\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7406\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7403\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7404\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7395\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7392\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7397\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7405\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7404\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7401\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob18K1xrsFkY",
        "outputId": "33e0022f-b1e1-4069-ebb4-893d33ac3a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5643 - accuracy: 0.7248 - 375ms/epoch - 1ms/step\n",
            "Loss: 0.5643035173416138, Accuracy: 0.7247577905654907\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EOYI-ehxIgC"
      },
      "source": [
        "Best yet - will add Tanh activation to another hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56KGgWMxJOB"
      },
      "source": [
        "## V5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVHs3l_UxgKG",
        "outputId": "62919b87-a5b6-4f2d-f262-bf54ef9da30d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 80)                3280      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 60)                4860      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 40)                2440      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 20)                820       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,621\n",
            "Trainable params: 11,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=60, activation=\"tanh\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=40, activation=\"gelu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
        "\n",
        "# Fourth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-ABGT_sLxbPL"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZhd-AcqxX3D",
        "outputId": "5e5fbde2-dd2a-4fdd-d603-b7cc5ea36c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5644 - accuracy: 0.7241\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.7318\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.7321\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7324\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7330\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7343\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7355\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7355\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7360\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7363\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7366\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7372\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7367\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7371\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7367\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7372\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7380\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7376\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7376\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7384\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7379\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7382\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7384\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7390\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7389\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7384\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7386\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7383\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7392\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7388\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7386\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7395\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7390\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7397\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7388\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7391\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7397\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7400\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7396\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7402\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7399\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7403\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7405\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7405\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7394\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7400\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7400\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7402\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hufXhGnxPO6",
        "outputId": "1c8c5867-e482-4782-f3cf-4966f7d92c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5619 - accuracy: 0.7249 - 394ms/epoch - 1ms/step\n",
            "Loss: 0.5618962645530701, Accuracy: 0.7248744964599609\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMh1YcTezDXh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcek6loNzC0B"
      },
      "source": [
        "## V6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-asWK3NzFs8",
        "outputId": "cf1d984b-c488-4b57-e731-01c45bc15c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 80)                3280      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 60)                4860      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 40)                2440      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 20)                820       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,671\n",
            "Trainable params: 11,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=60, activation=\"tanh\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=40, activation=\"gelu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=20, activation=\"gelu\"))\n",
        "\n",
        "# Fourth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
        "\n",
        "# Fifth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tWUCfyqYzllh"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nt-kO1xzh2u",
        "outputId": "ce217085-5e74-4323-f4b8-660f3a7b3248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5673 - accuracy: 0.7201\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5521 - accuracy: 0.7306\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7315\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7332\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7349\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7351\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7346\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7357\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7358\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7350\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7360\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7366\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7366\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7368\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7368\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7377\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7372\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7369\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7380\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7377\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7383\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7380\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7377\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7381\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7378\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7378\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7388\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7388\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7396\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7393\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7390\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7397\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7389\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7393\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7400\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7392\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7408\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7394\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7398\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7399\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7396\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7404\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7397\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7399\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7402\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7403\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7402\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7403\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7402\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7396\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7403\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7405\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7401\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7405\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7402\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7403\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7401\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7411\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7407\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7407\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7408\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7410\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7397\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7407\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7407\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7414\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7404\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7406\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7409\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7420\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7416\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7407\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7416\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7404\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7407\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7412\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7410\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7409\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7409\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7415\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7406\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7416\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7409\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7419\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7418\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7412\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7418\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7405\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7411\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7413\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7408\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7413\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7417\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7411\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7414\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7423\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7404\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7418\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7419\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7416\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt_AA3U-zdgC",
        "outputId": "4f9c0c2a-3af1-44e3-be98-c74eda1a5edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5718 - accuracy: 0.7239 - 398ms/epoch - 1ms/step\n",
            "Loss: 0.5717784762382507, Accuracy: 0.7239407300949097\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7z6eBDvBm6i"
      },
      "source": [
        "## V7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyrotuP2Bhay",
        "outputId": "875282bd-803f-4dc3-f23f-2b05e5d6986d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 200)               8200      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 80)                8080      \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 50)                4050      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,781\n",
            "Trainable params: 90,781\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# Initialize model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=200, activation=\"relu\", input_dim=40))\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=200, activation=\"tanh\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=100, activation=\"gelu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=100, activation=\"gelu\"))\n",
        "\n",
        "# Fourth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\"))\n",
        "\n",
        "# Fifth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uT1InedVBvJJ"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUdN8wyDBzD8",
        "outputId": "6edbefd8-4619-4997-bfa1-60447d6c29b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5672 - accuracy: 0.7228\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5565 - accuracy: 0.7288\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5527 - accuracy: 0.7307\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5508 - accuracy: 0.7322\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5503 - accuracy: 0.7325\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5483 - accuracy: 0.7325\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7341\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5468 - accuracy: 0.7327\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5466 - accuracy: 0.7337\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7335\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5460 - accuracy: 0.7350\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7357\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7346\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7365\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7357\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7365\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7370\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5414 - accuracy: 0.7369\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7371\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5412 - accuracy: 0.7375\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5409 - accuracy: 0.7367\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5407 - accuracy: 0.7371\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7376\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7382\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7374\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7366\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7336\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7350\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7384\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7388\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7374\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7367\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7393\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7379\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7378\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7362\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5371 - accuracy: 0.7380\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7393\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5363 - accuracy: 0.7380\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5365 - accuracy: 0.7386\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5357 - accuracy: 0.7400\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5353 - accuracy: 0.7400\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5353 - accuracy: 0.7393\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7371\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7378\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5344 - accuracy: 0.7398\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5349 - accuracy: 0.7404\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7400\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7350\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5346 - accuracy: 0.7399\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdrNDaC4BrUN",
        "outputId": "af759136-6acd-4152-c1db-e3f407a3441e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5641 - accuracy: 0.7270 - 464ms/epoch - 2ms/step\n",
            "Loss: 0.5640567541122437, Accuracy: 0.7269756197929382\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XivSiIFhFLp0"
      },
      "source": [
        "This one is the best - Will save to HDF5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vRcf6aCIQYjL"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('/content/drive/MyDrive/deep-learning-challenge/AlphabetSoupCharity_Optimization.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Report on the Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The purpose of this analysis is to present an overview of the results of the foundation funding application binary classifier built for Alphabet Soup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing\n",
        "- Target Variables: A successful or unsuccessful funded project\n",
        "- Features for the model:\n",
        "    - APPLICATION TYPE\n",
        "    - AFFILIATION\n",
        "    - CLASSIFICATION OF APPLICANT\n",
        "    - USE CASE FOR FUNDS\n",
        "    - ORGANIZATION\n",
        "    - INCOME AMT\n",
        "    - ASK_AMT \n",
        "\n",
        "- Variables that are neither targets nor features and should be removed\n",
        "    - EIN, \n",
        "    - NAME, \n",
        "    - STATUS,\n",
        "    - SPECIAL_CONSIDERATIONS.\n",
        "\n",
        "### Compiling, Training, and Evaluating the Model\n",
        "- How many neurons, layers and activation functions did you select for model, and why\n",
        "    - Input layer had 200 neurons, with the relu activation as it's the best activation function to initialize a network with\n",
        "    - the output layer had 1 neuron and a sigmoid activation as it's the best to end on for a binary classifier.\n",
        "    - There were 5 hidden layers with 200, 100, 100, 80, and 50 neurons (in that order), and with activation functions tanh, gelu, gelu, relu, and relu.\n",
        "        for these I continued to add layers and neurons in the hope that a more layers and neurons would help to handle the level of complexity of the problem and so that my total layers (7) would match the total number of features.\n",
        "\n",
        "- I was unable to achieve the target model performance of 75%, achieving instead a max test score of 72.4% accuracy - however this was NOT from lack of trying.\n",
        "- In order to try and increase model performance I did a number of things:\n",
        "    - First I, removed some of the features that were very unbalanced by dropping the rows with the lowest occurences and removing the column entierly.\n",
        "    - then I, added more layers and varied activation functions\n",
        "    - And I also tried adding more neurons per layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall the model performed at 72.4% testing accuracy. Should I continue to try and optimize classification accuracy I would consider trying some Ensemble algorithms like Random Forest or Extra Trees and see if accuracy would improve. I would also try and create a more balanced dataset by duplicating rows at random in the under represented category to provide less bias. \n",
        "\n",
        "Next, I would re-bin the ask amount into 3 bins and remove some of the outliers as that would be contributing to lowered model prediction performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "AlphabetSoupCharity_Optimzation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
